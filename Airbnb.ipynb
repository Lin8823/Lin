{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airbnb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNEuDpKhg3Ss9ynoocMxhpy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lin8823/Lin/blob/main/Airbnb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpaURqdEbGjO"
      },
      "source": [
        "擷取評論欄位、清洗資料（欄位中nan）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcUCju44aziY"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "test=[]\n",
        "df = pd.read_csv(\"reviews.csv\")\n",
        "comments = list(df['comments'])\n",
        "newlist = [x for x in comments if pd.isnull(x) == False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-om8SQzeNr6"
      },
      "source": [
        "#### 將評論分為中文和英文、分別處理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xoyi7QspbXZd"
      },
      "source": [
        "中文字體轉換、清洗"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KAcyXEPbUi7"
      },
      "source": [
        "!pip install opencc-python-reimplemented"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ks8Ts7bhK5"
      },
      "source": [
        "from opencc import OpenCC\n",
        "cc = OpenCC('s2t')\n",
        "clear=[]\n",
        "for i in newlist:\n",
        "  pattern = re.sub('[^\\u4e00-\\u9fa5]', '', i)\n",
        "  clear.append(cc.convert(pattern))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWcCNC4teou1"
      },
      "source": [
        "Jieba分詞"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eghLRPwYerNq"
      },
      "source": [
        "!pip install jieba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd3G437WesxU"
      },
      "source": [
        "import jieba\n",
        "new_list=[]\n",
        "for str in clear:\n",
        "  seg_list = jieba.cut(str,use_paddle=True)\n",
        "  temp = list(seg_list)\n",
        "  if temp!=[]:\n",
        "    new_list.append(temp)\n",
        "    print(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89T3SZ3lfq02"
      },
      "source": [
        "設停用字，過濾不重要且重複性高的詞"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjbxFvBQgEgu"
      },
      "source": [
        "import nltk\n",
        "word_list = []\n",
        "file_name = '停用詞.txt'\n",
        "with open(file_name,'r', encoding = 'utf-8') as f:\n",
        "    stop_words = f.readlines()\n",
        "stop_words = [stop_word.rstrip() for stop_word in stop_words]\n",
        "for j in range(len(new_list)):\n",
        "  for i in new_list[j]:\n",
        "    if i not in stop_words:\n",
        "      word_list.append(i)\n",
        "wordfrequency = nltk.FreqDist(word_list)\n",
        "df = pd.DataFrame(list(wordfrequency.items()),columns=['字詞','頻率'])\n",
        "df_sort = df.sort_values(['頻率'],ascending=False)\n",
        "new_df_ch = df_sort[1:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sbOfDTmxD_P"
      },
      "source": [
        "中文詞頻畫圖"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eDHzpiyxIYc"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.barh(df['字詞'], df['頻率'], tick_label=df['字詞'])\n",
        "plt.savefig('中文詞頻.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdAKfkwlBpWr"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV-O8p3ceCuU"
      },
      "source": [
        "英文資料清洗"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg0p8ODwegpn"
      },
      "source": [
        "clear_en=[]\n",
        "for i in newlist:\n",
        "  pattern = re.sub('[^a-z^A-Z]', ' ', i)\n",
        "  clear_en.append(pattern)\n",
        "print(clear_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fskyBPtze2Ow"
      },
      "source": [
        "Jieba分詞"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqX-5Em8e4qj"
      },
      "source": [
        "new_list_en=[]\n",
        "for str in clear_en:\n",
        "  seg_list = jieba.cut(str,use_paddle=True)\n",
        "  # if list(seg_list)!=[]:\n",
        "  temp = list(seg_list)\n",
        "  if temp!=[]:\n",
        "    new_list_en.append(temp)\n",
        "    print(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HOiW6mygLUD"
      },
      "source": [
        "設英文停用詞  \n",
        "NLTK計算詞頻"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rDPGXCHgNsM"
      },
      "source": [
        "import nltk\n",
        "word_list_en = []\n",
        "file_name = 'stop.txt'\n",
        "with open(file_name,'r', encoding = 'utf-8') as f:\n",
        "    stop_words = f.readlines()\n",
        "stop_words = [stop_word.rstrip() for stop_word in stop_words]\n",
        "for j in range(len(new_list_en)):\n",
        "  for i in new_list_en[j]:\n",
        "    if i not in stop_words:\n",
        "      word_list_en.append(i)\n",
        "wordfrequency_en = nltk.FreqDist(word_list_en)\n",
        "df = pd.DataFrame(list(wordfrequency_en.items()),columns=['word','frequency'])\n",
        "df_sort = df.sort_values(['frequency'],ascending=False)\n",
        "new_df = df_sort[1:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP62Jcm7xd6N"
      },
      "source": [
        "英文詞頻畫圖"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW80oUMvxiEq"
      },
      "source": [
        "plt.barh(new_df['word'], new_df['frequency'], tick_label=new_df['word'])\n",
        "plt.savefig('chart.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}