# -*- coding: utf-8 -*-
"""land_pyspark.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aeInu0q3NTd4pgGRBorCpMTxalY7iiXH
"""

!pip install pyspark

from pyspark.context import SparkContext,SparkConf
from pyspark.sql.session import SparkSession
from pyspark.sql import SQLContext
from pyspark.sql import HiveContext
from pyspark.sql.functions import *
from pyspark.sql.types import StringType
from pyspark.sql.functions import concat

spark = SparkSession.\
            builder.\
            getOrCreate()

path = ['/content/A_lvr_land_A.csv', '/content/B_lvr_land_A.csv', '/content/E_lvr_land_A.csv', '/content/F_lvr_land_A.csv', '/content/H_lvr_land_A.csv']
df = spark.read.csv(path, header=True)

chinese_dict ={'零':0, '一':1, '二':2, '兩':2, '三':3, '四':4, '五':5, '六':6, '七':7, '八':8, '九':9, '十':10, 
                           '百':100, '千':1000, '萬':10000, '億':100000000}
def transform(uchars_chinese):
  total = 0
  r = 1              #表示單位：個十百千...
  try:
    for i in range(len(uchars_chinese) - 2, -1, -1): #排除資料中的"層"這個字後，從個位數開始進行數字轉換
      val = chinese_dict.get(uchars_chinese[i])
      if val >= 10 and i == 0:  #for 十開頭的，十三、十四、十*
        if val > r: #若大於現在的單位
          r = val #指派給r，進行下一輪單位比較或運算
          total = total + val
        else:
          r = r * val
      elif val >= 10:
        if val > r:
          r = val
        else:
          r = r * val
      else:
        total = total + r * val
  except TypeError:
    pass

  return total
transformUDF = udf(lambda z: transform(z)) 
df = df.withColumn("總樓層數_fix", transformUDF(df.總樓層數)) #使用自訂義函數轉換數字
df=df.filter((df.主要用途=='住家用') & (df.建物型態.rlike("住宅大樓.") & (df.總樓層數_fix >=13))).sort(desc('交易年月日')) #【主要用途】為【住家用】、【建物型態】為【住宅大樓】、【總樓層數】需【大於等於十三層】
df.show()

df.write.mode('overwrite').json('/content/result')